See https://arxiv.org/abs/2409.11149
SAGED: A Holistic Bias-Benchmarking Pipeline for Language Models with Customisable Fairness Calibration
![image](https://github.com/user-attachments/assets/76fdb7fa-a4e7-4b1b-bd4d-0f47743fde5d)
