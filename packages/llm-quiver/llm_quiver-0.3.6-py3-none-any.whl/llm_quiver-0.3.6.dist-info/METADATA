Metadata-Version: 2.1
Name: llm-quiver
Version: 0.3.6
Summary: The auxiliary tool is used to invoke the online LLM service API, supporting local caching, prompt rendering, and configuration management.
Author: xrandx
Author-email: kevtyle@hotmail.com
Requires-Python: >=3.8,<4.0
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Dist: loguru (>=0.7.0,<0.8.0)
Requires-Dist: openai (>=1.28.0,<2.0.0)
Requires-Dist: pyyaml (>=6.0.2,<7.0.0)
Requires-Dist: tiktoken (==0.7.0)
Requires-Dist: toml (>=0.10.2,<0.11.0)
Requires-Dist: tqdm (>=4.66.0,<5.0.0)
Description-Content-Type: text/markdown

# LLMQuiver

The auxiliary tool is used to invoke the online LLM service API, supporting local caching, prompt rendering, and configuration management.


## Supported
- Support Openai/Azure LLM service providers (or openai-compatible service providers).
- Local caching (based on sqlite).
- Prompt rendering (based on toml and jinja2).
- Configuration management (based on toml).

## To Be Done
- Multi service provider support.
