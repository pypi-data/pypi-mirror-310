[tool.poetry]
name = "giotto_llm"
version = "0.0.1"
description = "Wrapper of many OS libraries to finetune LLMs and run them in inference mode efficiently."
readme = "README.md"
authors = ["Gabriele Beltramo <g.beltramo@giotto.ai>", "Matteo Caorsi <m.caorsi@giotto.ai>, Wallyson Lemes de Oliveira <w.lemes@giotto.ai>, Mekhron Bobokonov <m.bobokonov@giotto.ai>"]

[build-system]
requires = ["poetry-core>=1.0.0"]
build-backend = "poetry.core.masonry.api"

[tool.poetry.dependencies]
python = ">=3.10,<4.0"
poetry = "~1.8.3"
numpy = "1.26.4"
scipy = "^1.14.1"
scikit-learn = "~1.3.2"
matplotlib = "^3.7.5"
psutil = "~5.9.3"
torch = "~2.4.0" # same as Kaggle with GPU notebook
transformers = "^4.45.1" # not same as Kaggle
sentencepiece = "~0.2.0"
huggingface-hub = "~0.23.4"
pydantic = "^2.9.2"
optimum = ">1.20.0"
json-fix = "~1.0.0"
gputil = "^1.4.0"
sphinx = "~8.1.3"
numpydoc = "~1.8.0"
sphinx-rtd-theme = "~3.0.2"

[tool.poetry.group.dev.dependencies]
polars = "^1.7.1"
build = "^1.2.2"
black = "^24.8.0"
pytest = "^8.3.2"
isort = "^5.13.2"
mypy = "^1.11.1"
easydict = "^1.13"
bumpver = "^2023.1129"
poetry-plugin-export = "^1.2.0"
mlflow = "^2.17.0"
google-cloud-storage = "1.44.0"
fire = "0.6.0"
# Fine-tuning packages
unsloth = "^2024.8"
triton = "^3.0.0"
trl = "^0.11.0"
datasets = "^3.0.1"
xformers = "~0.0.23"
accelerate = "^1.0.0"
bitsandbytes = "^0.44.0"
peft = "^0.13.0"
protobuf = "^3.20.0"
types-psutil = "^6.0.0.20240901"
qwen-vl-utils = "^0.0.8"
torchvision = "^0.19"
liger_kernel = "^0.3.1"
torch-pruning = "*"

[tool.poetry.group.optional.dependencies]
ipykernel = "^6.29.5"
jupyter = "^1.1.1"
ipython = "^8.28.0"
flash_attn = {url = "https://github.com/Dao-AILab/flash-attention/releases/download/v2.6.3/flash_attn-2.6.3+cu123torch2.4cxx11abiFALSE-cp310-cp310-linux_x86_64.whl"} # faster attention for some models on >Ampere gpus

[tool.isort]
profile = "black"
line_length = 100
known_first_party = ["llm_prompts"]
known_local_folder = ["llm_prompts"]

[tool.black]
line-length = 100
target-version = ["py310"]

[tool.mypy]
warn_return_any = true
warn_unused_configs = true
warn_redundant_casts = true
warn_unused_ignores = true
warn_unreachable = true
disallow_untyped_defs = true
disallow_untyped_calls = true
check_untyped_defs = true
strict_optional = true


exclude = [
  "llm_prompts/bucket/serialize.py",
  "llm_prompts/bucket/__main__.py",
]

[[tool.mypy.overrides]]
module = [
  "easydict",
  "torch",
  "transformers",
  "google",
  "unsloth",
  "unsloth.chat_templates",
  "tqdm",
  "datasets",
  "datasets.features",
  "trl",
  "peft",
  "pydantic",
  "mlflow",
  "transformers.generation",
  "huggingface_hub._login",
  "psutil",
  "accelerate",
  "pandas",
  "qwen_vl_utils",
  "transformers.models.qwen2_vl.modeling_qwen2_vl",
  "json_fix",
  "torch_pruning",
  "transformers.utils",
  "GPUtil",
  "sklearn.model_selection",
]
ignore_missing_imports = true

[tool.bumpver]
version_pattern = "MAJOR.MINOR.PATCH"
current_version = "0.1.84"
[tool.bumpver.file_patterns]
"pyproject.toml" = ['^version = "{version}"$', 'current_version = "{version}"$']
"llm_prompts/__init__.py" = ['^__version__ = "{version}"$']
"llm_prompts/tests/test_version.py" = [
  '^    assert llm_prompts.__version__ == "{version}"$',
]
