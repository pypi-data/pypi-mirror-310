Metadata-Version: 2.3
Name: chainchat
Version: 0.1a2
Summary: Chat with LangChain LLM models, with tool calling and multimodal support
Author-email: Andrew Wason <rectalogic@rectalogic.com>
Classifier: License :: OSI Approved :: GNU Affero General Public License v3 or later (AGPLv3+)
Requires-Python: >=3.12
Requires-Dist: click~=8.1.7
Requires-Dist: httpx~=0.27.2
Requires-Dist: langchain-core~=0.3.13
Requires-Dist: langgraph-checkpoint-sqlite~=2.0.1
Requires-Dist: langgraph~=0.2.39
Requires-Dist: platformdirs~=4.3.6
Requires-Dist: pydanclick~=0.3.0
Requires-Dist: python-dotenv~=1.0.1
Requires-Dist: pyyaml~=6.0.2
Requires-Dist: rich~=13.9.3
Provides-Extra: anthropic
Requires-Dist: langchain-anthropic~=0.2.4; extra == 'anthropic'
Provides-Extra: google
Requires-Dist: langchain-google-genai~=2.0.4; extra == 'google'
Provides-Extra: groq
Requires-Dist: langchain-groq~=0.2.1; extra == 'groq'
Provides-Extra: huggingface
Requires-Dist: langchain-huggingface~=0.1.2; extra == 'huggingface'
Provides-Extra: openai
Requires-Dist: langchain-openai~=0.2.5; extra == 'openai'
Provides-Extra: tools
Requires-Dist: langchain-community~=0.3.5; extra == 'tools'
Description-Content-Type: text/markdown

# ChainChat - Chat with LangChain
![ChainChat logo](chainchat.svg)

CLI to chat with any [LangChain](https://python.langchain.com/docs/introduction/) model,
also supports [tool calling](https://python.langchain.com/docs/integrations/tools/)
and [multimodality](https://python.langchain.com/docs/concepts/multimodality/).

## Chat Models

ChainChat will introspect any installed `langchain_*` packages and make any `BaseChatModel` subclasses
available as commands with the models attributes as options - `chainchat <model-command> --<option> <value>`.

Just `pip install` any model packages you want to use, and they will be available as model commands to chat with:
```sh-session
$ chainchat chat
...
Commands:
  preset  Load a preset model from YAML.
$ pip install langchain_openai langchain_anthropic
$ chainchat chat
...
Commands:
  preset                          Load a preset model from YAML.
  anthropic                       See...
  anthropic-messages              See...
  azure-open-ai                   See...
...
```

## API Keys

API keys are accessed via environment variables.
By default they are loaded from a `.env` file located in the current directory.
You can specify a different file using the `chainchat --dotenv` option.

## OpenAI Compatible Models

You can use any OpenAI compatible model with ChainChat.
For example to use [xAI Grok](https://x.ai/api) put your `XAI_API_KEY` in your `.env` file
and alias it to `OPENAI_API_KEY`:
```sh-session
$ chainchat --alias-env OPENAI_API_KEY XAI_API_KEY chat --tool read_file --prompt "Read and summarize the file ./LICENSE.txt" open-ai --model-name grok-beta --openai-api-base https://api.x.ai/v1
I am reading the file ./LICENSE.txt to summarize its contents.
...
```