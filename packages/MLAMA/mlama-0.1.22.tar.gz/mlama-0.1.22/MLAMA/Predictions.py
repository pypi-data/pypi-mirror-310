# -*- coding: utf-8 -*-
"""Predictions.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R_OWOjyFLje8iOhoCfpmJmMRDhOX6tLu
"""

#### Prediction on Wave 1,2,3 Data [Prediction 1,2,3,4,5,6 weeks]

#tuned_model_dict contains param for specific delay, wave all models

from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.statespace.sarimax import SARIMAX
from .Models import stats_data, ARIMA_model, ml_model, gen_ml, arima_res_xgb, check_stationarity
from sklearn.metrics import mean_absolute_percentage_error
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
import pandas as pd
import numpy as np

def wave_prediction(delay_definition_flag, delayed_start_matrix, max_prediction_length, prediction_length, delay, WAVE, waveID, training_period, lag_reserve, lagged_amount, overlap, confidence_interval, tuned_model_dict):
  """
  Predicts the weekcase for each prediction_lenght and wave data using the given models. (what about delay??)
  Args:
    delay_definition_flag: Which definition of the delay. True=Yushu, False=JMM new definition.
    prediction_length: The length of the prediction.
    max_prediction_length: The maximum length of the predictions.
    delay: The delay in weeks.
    WAVE: the wave object
    waveID: The ID of the wave.#don't need both, we can only use waveID?
    training_period: The length of the data to fit from the latest training period.
    lag_reserve: The length of the lag reserve. controls how much data is reserved for testing = 6
    lagged_amount: The length of the lagged amount. how much past data is used for prediction =  5
    tuned_model_dict: The dictionary of tuned models, contains all the tuned parameters.
  Returns:
    metric_row: containing all different metrics: xgb, rf, xgb_resid, xgb_resid_predict, arima_df, arima_mape, xgb_resid_mape, xgb_mape, rf_mape, arima_list, RF_list, xgb_list, xgb_resid_list
  """
  print("prediction_length: ", prediction_length, "delay: ", delay, "Wave: ", waveID)
  #wave, train, test = WAVE.get_wave_dates_with_delay(delay, delay_definition_flag)#wave, train, test data calculated incorporating delay
  wave, train, test = WAVE.get_wave_dates_with_delay(delay, delayed_start_matrix, delay_definition_flag)
  #print('test ', test.shape)
  single_train, full_train, fit_weeks_stat = stats_data(train) #single_ means only one feature weekcase is used

  single_test, full_test, pred_weeks_stat = stats_data(test.head(prediction_length))
  #print('**fit_pred_weeks_stat')
  fit_pred_weeks_stat = pd.concat([fit_weeks_stat.tail(training_period), pred_weeks_stat], axis = 0).reset_index(drop = True)

  #print(fit_pred_weeks_stat.shape)
  fit_pred_y_STAT = pd.concat([single_train[-training_period:], single_test], axis = 0).reset_index(drop = True)

  #### Will do both for tscv1 and tscv2
  tuned_model_name = 'res'#not needed, not used
  key = 'wave '+str(wave)+' delay '+str(delay)+tuned_model_name
  key = tuned_model_name
  tuned_params = tuned_model_dict[key]

  tuned_model_name = 'ARIMA'
  key = 'wave '+str(wave)+' delay '+str(delay)+tuned_model_name
  key = tuned_model_name
  arima_order = tuned_model_dict[key]['order'].iloc[0]
  arima_seasonal_order = tuned_model_dict[key]['seasonal_order'].iloc[0]
  arima_order_list = ()
  arima_seasonal_order_list = ()
  s = arima_order.split(',')#because its a string

  arima_order_list = (int(s[0].split('(')[1]),int(s[1]),int(s[2].split(')')[0]))

  s = arima_seasonal_order.split(',')
  arima_seasonal_order_list = (int(s[0].split('(')[1]),int(s[1]),int(s[2]),int(s[3].split(')')[0]))


  #single_train = single_train.diff().dropna()

  # Check if the differenced series is stationary
  #check_stationarity(single_train)

  ARMAmodel = SARIMAX(single_train,order=arima_order_list,seasonal_order=arima_seasonal_order_list)# change in order (2, 0, 1) for delaay =0
  arima_mse,arima_rmse,arima_mae,arima_mape,arima_list,arima,arimap,arimaf = ARIMA_model(ARMAmodel,single_test,training_period+prediction_length,confidence_interval)
  print(arima_list)
  ### Generate Machine Learning Data, has previous lagged_amount= how far in the past I will look. five time points as inputs
  #prediction_length = test_length in the function
  train_x,test_x,train_y,test_y, fit_weeks_ml, pred_weeks_ml = gen_ml(wave,prediction_length, lagged_amount, prediction_length, max_prediction_length, resid = False)

  #print('**fit_weeks_stat', fit_weeks_stat.shape)
  #print(fit_weeks_stat.tail(1))
  #print('**fit_pred_y_STAT')
  #print(fit_pred_y_STAT)
  #print('**fit_weeks_ml', fit_weeks_ml.shape)
  #print(fit_weeks_ml.tail(1))

  #print('**single_test')
  #print(single_test )
  #print(fit_pred_weeks_stat)
  #print('**pred_weeks_stat')
  #print(pred_weeks_stat)
  #print('**pred_weeks_ml')
  #print(pred_weeks_ml)
  #print('**test_y')
  #print(test_y)
  #print('**fit_pred_y_ML')
  fit_pred_weeks_ml = pd.concat([fit_weeks_ml.tail(training_period), pred_weeks_ml], axis = 0).reset_index(drop = True)
  fit_pred_y_ML = pd.concat([train_y[-training_period:], test_y], axis = 0).reset_index(drop = True)
  #print(fit_pred_weeks_ml)

  #print(fit_pred_y_ML.shape)
  #### Random Forest Model
  tuned_model_name = 'forest_42'
  key = 'wave '+str(wave)+' delay '+str(delay)+tuned_model_name
  key = tuned_model_name
  max_depth = tuned_model_dict[key]['max_depth'].iloc[0]
  max_features = tuned_model_dict[key]['max_features'].iloc[0]
  min_samples_split = tuned_model_dict[key]['min_samples_split'].iloc[0]
  n_estimators = tuned_model_dict[key]['n_estimators'].iloc[0]

  RF_model = RandomForestRegressor(max_depth =max_depth, max_features= max_features,min_samples_split = min_samples_split, n_estimators= n_estimators,random_state= 42).fit(train_x,train_y)
  RF_list,rf_mse,rf_rmse,rf_mae,rf_mape, rf_predict = ml_model(test_x,test_y,RF_model,train)
  rf_fit = pd.DataFrame(RF_model.predict(train_x)).reset_index(drop = True).tail(training_period)#training_period here prediction on training data
  rf_pre = pd.DataFrame(RF_model.predict(test_x)).reset_index(drop = True)# rf_pre and rf_predict are the same, not sure what's the reason to calculate again
  #print('**rf')
  rf = pd.concat([rf_fit,rf_pre],axis=0)



  #print(rf.shape)
  #### XGBoost Model
  tuned_model_name = 'XGB_42'
  key = 'wave '+str(wave)+' delay '+str(delay)+tuned_model_name
  key = tuned_model_name
  booster = tuned_model_dict[key]['booster'].iloc[0]
  learning_rate = tuned_model_dict[key]['learning_rate'].iloc[0]
  n_estimators = tuned_model_dict[key]['n_estimators'].iloc[0]

  xgb =  XGBRegressor(booster = booster, learning_rate = learning_rate, n_estimators = n_estimators).fit(train_x,train_y)
  xgb_predict = xgb.predict(test_x) #Predictions on testing data
  xgb_list = np.abs(xgb_predict - test_y)/test_y
  xgb_p =  pd.DataFrame(xgb_predict)
  xgb_p = xgb_p.reset_index(drop = True)
  xgb_f = xgb.predict(train_x)
  xgb_f = pd.DataFrame(xgb_f).tail(training_period)#26 again???? training_pertiod
  xgb_f = xgb_f.reset_index(drop=True)
  #print('**xgb')
  xgb = pd.concat([xgb_f,xgb_p],axis=0)


  #print(xgb.shape)

  xgb_mape = mean_absolute_percentage_error(wave.weekcase[-len(xgb_predict):].values,xgb_predict[:])

  #### XGBoost On ARIMA residual

  #xgb_resid, xgb_resid_predict,arima_resid, xgb_resid_list, xgb_resid_p, xgb_resid_f = arima_res_xgb(ARMAmodel, pd.DataFrame(wave.weekcase),single_train,single_test,training_period+prediction_length,lagged_amount,training_period, overlap, confidence_interval, lag_reserve, resid = True, booster = "gbtree", learning_rate = 0.05, n_estimators = 2)
  #print("**xgb_resid: Shapes:", xgb_resid_predict.shape, arima.tail(prediction_length).shape, len(xgb_resid_predict))
  #xgb_resid_mape = mean_absolute_percentage_error(wave.weekcase[-len(xgb_resid_predict):].values,xgb_resid_predict[:]+arima.tail(prediction_length))#i think this is the problem
  xgb_resid = {}
  xgb_resid_predict = {}
  arima_resid = {}
  xgb_resid_mape = {}
  xgb_resid_list = {}
  xgb_resid_p = {}
  xgb_resid_f = {}
  arima_df = pd.DataFrame(arima, columns=[str(delay)])

  xgb = xgb.reset_index(drop = True)

  rf = rf.reset_index(drop = True)
  #xgb_resid = xgb_resid.reset_index(drop = True)
  arima = arima.reset_index(drop = True)
  arima_df = arima_df.reset_index(drop = True)


  data = { 'wave': waveID, 'delay': delay, 'prediction_length':prediction_length, 'weekML': [fit_pred_weeks_ml], 'weekSTAT': [fit_pred_weeks_stat], 'Observed_fit_train_pred_test_STAT': [fit_pred_y_STAT], 'Observed_fit_train_pred_test_ML': [fit_pred_y_ML], 'xgb_p': [xgb_p], 'arimap': [arimap], 'rf_pre': [rf_pre],'xgb': [xgb], 'rf': [rf], 'xgb_resid': [xgb_resid], 'xgb_resid_predict': [xgb_resid_predict],'arima': [arima_df], 'xgb_resid_mape': [xgb_resid_mape], 'xgb_mape':[xgb_mape], 'arima_mape': [arima_mape], 'rf_mape': [rf_mape], 'arima_list' : [arima_list], 'RF_list':[RF_list], 'xgb_list':[xgb_list], 'xgb_resid_list': [xgb_resid_list]}
  metric_row = pd.DataFrame(data)
  #print('ARIMA: ', arima_df.shape, 'XGB: ', xgb.shape)
  return metric_row#xgb, rf, xgb_resid, xgb_resid_predict, arima_df, arima_mape, xgb_resid_mape, xgb_mape, rf_mape, arima_list, RF_list, xgb_list, xgb_resid_list