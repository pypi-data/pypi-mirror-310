Metadata-Version: 2.1
Name: DeepTuner
Version: 0.1.1
Summary: A package for fine-tuning deep learning models with Siamese architecture and triplet loss
Home-page: https://github.com/Devasy23/DeepTuner
Author: Devasy Patel
Author-email: patel.devasy.23@gmail.com
License: UNKNOWN
Platform: UNKNOWN
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: BSD License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.7
Description-Content-Type: text/markdown
Requires-Dist: tensorflow>=2.12.0
Requires-Dist: numpy>=1.21.0
Requires-Dist: scikit-learn>=1.0.0
Requires-Dist: Pillow>=9.0.0
Requires-Dist: wandb>=0.15.0
Requires-Dist: efficientnet>=1.0.0
Requires-Dist: facenet-pytorch>=2.5.0
Requires-Dist: requests>=2.31.0
Requires-Dist: tqdm>=4.65.0

# DeepTuner

## Description

DeepTuner is an open source Python package for fine-tuning computer vision (CV) based deep models using Siamese architecture with a triplet loss function. The package supports various model backbones and provides tools for data preprocessing and evaluation metrics.

## Installation

To install the package, use the following command:

```bash
pip install DeepTuner
```

## Usage

### Fine-tuning Models with Siamese Architecture and Triplet Loss

Here is an example of how to use the package for fine-tuning models with Siamese architecture and triplet loss:

```python
import DeepTuner
from DeepTuner import triplet_loss, backbones, data_preprocessing, evaluation_metrics

# Load and preprocess data
data = data_preprocessing.load_data('path/to/dataset')
triplets = data_preprocessing.create_triplets(data)

# Initialize model backbone
model = backbones.get_model('resnet')

# Compile model with triplet loss
model.compile(optimizer='adam', loss=triplet_loss.triplet_loss)

# Train model
model.fit(triplets, epochs=10, batch_size=32)

# Evaluate model
metrics = evaluation_metrics.evaluate_model(model, triplets)
print(metrics)
```

For more detailed usage and examples, please refer to the documentation.


