{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b81fa87",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Statistical Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83129df-20c1-419f-b629-f6c546af7ebd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import RandomState\n",
    "\n",
    "from azcausal.core.panel import CausalPanel\n",
    "from azcausal.core.effect import get_true_effect\n",
    "from azcausal.core.error import JackKnife\n",
    "from azcausal.core.parallelize import Joblib\n",
    "from azcausal.data import CaliforniaProp99\n",
    "from azcausal.estimators.panel.did import DID\n",
    "from azcausal.util import zeros_like\n",
    "from azcausal.util.analysis import f_power"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265b7226-ad95-4d5b-b734-4d286f9afef1",
   "metadata": {
    "tags": []
   },
   "source": [
    "First, let us load the data you want to analyze the power on. Make sure that no units are already treated in this data set at anytime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c4ef24-e3b2-4737-82bc-3fc844db214b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "panel = CaliforniaProp99().panel().filter(contr=True)\n",
    "\n",
    "print(panel.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2165a21-4c68-42fe-a404-33bc98bfee54",
   "metadata": {
    "tags": []
   },
   "source": [
    "Next, we define a function which will create a sample of our original panel and add some treatment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e121ad99-e837-417b-adbf-0ece86a0d7e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class Function:\n",
    "\n",
    "    def __init__(self, panel, att, seed) -> None:\n",
    "        super().__init__()\n",
    "        self.panel = panel\n",
    "        self.att = att\n",
    "        self.seed = seed\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        panel = self.panel\n",
    "            \n",
    "        # parameters\n",
    "        seed = self.seed\n",
    "        att = self.att\n",
    "\n",
    "        # constants\n",
    "        conf = 90\n",
    "        n_treat = 5\n",
    "        n_post = 12\n",
    "\n",
    "        # random seed for reproducibility\n",
    "        random_state = RandomState(seed)\n",
    "\n",
    "        # define what is treated and when\n",
    "        treat_units = random_state.choice(np.arange(panel.n_units()), replace=False, size=n_treat)\n",
    "\n",
    "        intervention = zeros_like(panel.intervention)\n",
    "        intervention.iloc[-n_post:, treat_units] = 1\n",
    "\n",
    "        te = panel.outcome * intervention * (att / 100)\n",
    "        outcome = panel.outcome + te\n",
    "\n",
    "        # create the new panel with the new intervention\n",
    "        panel = CausalPanel(data=dict(intervention=intervention, te=te, outcome=outcome)).setup()\n",
    "\n",
    "        # use the estimator to get the effect\n",
    "        true_effect = get_true_effect(panel)\n",
    "\n",
    "        # run the estimator to get the predicted effect\n",
    "        estimator = DID()\n",
    "        result = estimator.fit(panel)\n",
    "        estimator.error(result, JackKnife())\n",
    "        pred_effect = result.effect\n",
    "\n",
    "        # create an output dictionary of what is true and what we have measured\n",
    "        res = dict(**pred_effect.to_dict(prefix='pred_', conf=conf), **true_effect.to_dict(prefix='true_', conf=conf))\n",
    "        res.update(dict(att=att, seed=seed))\n",
    "\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53d8e56-fbca-4b7e-8f30-76f90d28d929",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Power"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115f277e-ba41-478d-bf5d-18e373c6fbcd",
   "metadata": {
    "tags": []
   },
   "source": [
    "Then, we create a generator which creates the runs. For each iteration we initialize the `Function`, we have defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef1eb68-b0f8-4ccd-a6f5-7ccf18b1e7c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# the number of samples used for measuring power\n",
    "n_samples = 100\n",
    "\n",
    "# create all runs for this analysis (this can potentially include more dimensions as well)\n",
    "def g_power():\n",
    "    for seed in range(n_samples):\n",
    "        yield panel, -20, seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b009a740-b9cd-47ac-be9f-f80a5ef2d26d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Because running this sequentially is usually pretty slow, we make use of the `Parallelize` interface in *azcausal* to speed things up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d2b34f-17a2-4751-a681-08ed90f74bf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parallelize = Joblib(prefer='processes', progress=True)\n",
    "results = parallelize.run([Function(*args) for args in g_power()])\n",
    "\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1587bf4b-8a45-4bb0-a04a-b538bf73b0dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "And then we can analyze the resulting power and also coverage of the confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ba7cc2-271e-4911-a2ae-3bffd5154123",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dx = (pd.DataFrame(results)\n",
    "      .assign(true_in_ci=lambda dd: dd['true_avg_te'].between(dd['pred_avg_ci_lb'], dd['pred_avg_ci_ub']))\n",
    "      .assign(avg_te_error=lambda dd: dd['true_avg_te'] - dd['pred_avg_te'])\n",
    "      .assign(rel_te_error=lambda dd: dd['true_rel_te'] - dd['pred_rel_te'])\n",
    "      )\n",
    "\n",
    "# get the power from the results\n",
    "power = f_power(dx.assign(sign=lambda dd: dd['pred_sign']))\n",
    "\n",
    "print(\"Power\")\n",
    "print(f\"(+) {power['+']:.2%}\")\n",
    "print(f\"(+/-) {power['+/-']:.2%}\")\n",
    "print(f\"(-) {power['-']:.2%}\")\n",
    "\n",
    "print()\n",
    "\n",
    "coverage = dx['true_in_ci'].mean()\n",
    "print(f\"Coverage: {coverage:.1%}\")\n",
    "\n",
    "avg_te_rmse = np.sqrt((dx['avg_te_error'] ** 2).mean())\n",
    "print(f\"Average TE RMSE: {avg_te_rmse}\")\n",
    "\n",
    "rel_te_rmse = np.sqrt((dx['rel_te_error'] ** 2).mean())\n",
    "print(f\"Relative TE RMSE: {rel_te_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7211ea8f-2599-46ba-8f09-7ac4fc6933cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Power Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d36a8d-69fa-453e-8e46-608c58512611",
   "metadata": {
    "tags": []
   },
   "source": [
    "We estimate our statistical power to be around 95% given the setup above. In addition, we might want to be a little more systematic and answer the question of how much power does a specific ATT parameter have (this can be extended to any parameter such as number of treatment regions or post time periods)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7739e53e-92fa-4cbc-90ab-80cc47542388",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def g_power_analysis():\n",
    "    for att in np.linspace(-30, 30, 13):\n",
    "        for seed in range(n_samples):\n",
    "            yield att, seed\n",
    "            \n",
    "\n",
    "parallelize = Joblib(prefer='processes', progress=True)\n",
    "results = parallelize.run([Function(panel, *args) for args in g_power_analysis()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdee8c4b-6956-47b4-a5ec-7579464fa022",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4869b1-5d83-4769-9ff7-db7a6481143c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dx = (pd.DataFrame(results)\n",
    "      .assign(true_in_ci=lambda dd: dd['true_avg_te'].between(dd['pred_avg_ci_lb'], dd['pred_avg_ci_ub']))\n",
    "      .assign(perc_te_error=lambda dd: dd['pred_perc_te'] - dd['true_perc_te'])\n",
    "      )\n",
    "\n",
    "# get the power and coverage for each group now\n",
    "pw = dx.assign(sign=lambda dd: dd['pred_sign']).groupby('att').apply(f_power).sort_index().reset_index()\n",
    "coverage = dx.groupby('att')['true_in_ci'].mean()\n",
    "error = dx.groupby('att').aggregate(mean=('perc_te_error', 'mean'), se=('perc_te_error', 'sem'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d989feaa-1f03-4ba7-889a-fbaa3604e3f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, (top, middle, bottom) = plt.subplots(3, 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "fig.suptitle(f'CaliforniaProp99', fontsize=16)\n",
    "\n",
    "top.plot(pw['att'], pw['-'], \"-o\", color=\"red\", label='-')\n",
    "top.plot(pw['att'], pw['+'], \"-o\", color=\"green\", label='+')\n",
    "top.plot(pw['att'], pw['+/-'], \"-o\", color=\"black\", label='+/-', alpha=0.5)\n",
    "top.axhline(1.0, color=\"black\", alpha=0.15)\n",
    "top.axhline(0.9, color=\"black\", alpha=0.15, linestyle='--')\n",
    "top.axhline(0.0, color=\"black\", alpha=0.15)\n",
    "top.set_ylim(-0.05, 1.05)\n",
    "top.set_xlabel(\"ATT (%)\")\n",
    "top.set_ylabel(\"Statistical Power\")\n",
    "top.legend()\n",
    "\n",
    "middle.plot(coverage.index, coverage.values, \"-o\", color=\"black\", label=\"coverage\")\n",
    "middle.axhline(1.0, color=\"black\", alpha=0.15)\n",
    "middle.axhline(0.0, color=\"black\", alpha=0.15)\n",
    "middle.set_ylim(-0.05, 1.05)\n",
    "middle.set_xlabel(\"ATT (%)\")\n",
    "middle.set_ylabel(\"Coverage\")\n",
    "middle.legend()\n",
    "\n",
    "\n",
    "bottom.plot(error.index, np.zeros(len(error)), color='black', alpha=0.7)\n",
    "bottom.plot(error.index, error['mean'], '-o', color='red')\n",
    "bottom.errorbar(error.index, error['mean'], error['se'], color='red', alpha=0.5, barsabove=True)\n",
    "bottom.set_xlabel(\"ATT (%)\")\n",
    "bottom.set_ylabel(\"Error\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17.209774,
   "end_time": "2023-12-08T00:23:33.054269",
   "environment_variables": {},
   "exception": null,
   "input_path": "/Users/blankjul/workspace/azcausal/docs/source/power.ipynb",
   "output_path": "/Users/blankjul/workspace/azcausal/docs/source/power.ipynb",
   "parameters": {},
   "start_time": "2023-12-08T00:23:15.844495",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
