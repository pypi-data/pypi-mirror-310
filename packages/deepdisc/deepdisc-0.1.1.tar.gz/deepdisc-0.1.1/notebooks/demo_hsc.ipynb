{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2a2dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "\n",
    "# from google.colab.patches import cv2_imshow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import LazyConfig\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data import build_detection_train_loader\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.engine import SimpleTrainer\n",
    "from detectron2.engine import HookBase\n",
    "from typing import Dict, List, Optional\n",
    "import detectron2.solver as solver\n",
    "import detectron2.modeling as modeler\n",
    "import detectron2.data as data\n",
    "import detectron2.data.transforms as T\n",
    "import detectron2.checkpoint as checkpointer\n",
    "from detectron2.data import detection_utils as utils\n",
    "import weakref\n",
    "import copy\n",
    "import torch\n",
    "import time\n",
    "\n",
    "import deepdisc.astrodet.astrodet as toolkit\n",
    "from deepdisc.astrodet import detectron as detectron_addons\n",
    "\n",
    "from deepdisc.data_format.file_io import DDLoader\n",
    "from deepdisc.data_format.annotation_functions.annotate_hsc import annotate_hsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fad3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the versions to test the imports and so we know what works\n",
    "print(detectron2.__version__)\n",
    "print(np.__version__)\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b2c4ad-3932-4a06-9166-c60fe4b53e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prettify the plotting\n",
    "#from astrodet.astrodet import set_mpl_style\n",
    "\n",
    "toolkit.set_mpl_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035b6246",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Register HSC training data\n",
    "\n",
    "First, format the HSC data using training_data.ipynb.  It will need to be partitioned in \"train, test and val\" directories\n",
    "\n",
    "The flexible `DDLoader` class can be used to load data from a generic directory \n",
    "structure into a user-defined output structure of metadata.\n",
    "\n",
    "For a custom dataset, this dictionary needs to be populated correctly for your data.\n",
    "\n",
    "You will need to change directory paths!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055b5ccc-fbf8-4960-bb7c-7d261fc20474",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dirpath = \"/home/shared/hsc/HSC/HSC_DR3/data/\"\n",
    "output_dir = \"./output/hsc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6958fcd1-5ce0-43f0-9eee-f2d877148036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this block is for debug purposes, set to -1 to include every sample\n",
    "sampleNumbers = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacacd46",
   "metadata": {},
   "source": [
    "We initialize a `DDLoader` for the train and test datasets. The `DDLoader.generate_filedict` function reads in data from a directory structure, the\n",
    "kwargs will need to be tuned to the particular structure of a given directory.\n",
    "This returns a dictionary of file-level information that can be passed along\n",
    "to an annotation generation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6731c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dictionary of file paths\n",
    "test_loader = DDLoader().generate_filedict(os.path.join(dirpath, 'test'), ['G', 'R', 'I'], '*_scarlet_img.fits', '*_scarlet_segmask.fits', n_samples=sampleNumbers)\n",
    "train_loader = DDLoader().generate_filedict(os.path.join(dirpath, 'train'), ['G', 'R', 'I'], '*_scarlet_img.fits', '*_scarlet_segmask.fits', n_samples=sampleNumbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb61c04",
   "metadata": {},
   "source": [
    "For detectron2 to read the data, it must be in a dictionary format. The\n",
    "`DDLoader` instances established above can generate annotations in dictionary\n",
    "format using the `DDLoader.generate_dataset_dict` function. This function\n",
    "passes a user-defined annotation function along to the files, using the \n",
    "filedicts generated above.\n",
    "\n",
    "In this case, we have a pre-made annotation function for HSC data,\n",
    "`annotate_hsc, which is passed along.\n",
    "\n",
    "However, this step can take a few minutes, and so we recommend only running it once and saving the dictionary data as a json file that can be read in at the beginning of your code.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfef1a4",
   "metadata": {},
   "source": [
    "Now, we register the dataset following the detectron2 documention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e81a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "DatasetCatalog.register(\"astro_train\", lambda: train_loader.generate_dataset_dict(annotate_hsc).get_dataset())\n",
    "astrotrain_metadata = MetadataCatalog.get(\"astro_train\").set(thing_classes=[\"object\"])\n",
    "DatasetCatalog.register(\"astro_test\", lambda: test_loader.generate_dataset_dict(annotate_hsc).get_dataset())\n",
    "astrotest_metadata = MetadataCatalog.get(\"astro_test\").set(thing_classes=[\"object\"])\n",
    "\n",
    "dataset_dicts = {}\n",
    "for i, d in enumerate([\"train\",\"test\"]):\n",
    "    print(f\"Loading {d}\")\n",
    "    loader = DDLoader().generate_filedict(os.path.join(dirpath, d), ['G', 'R', 'I'], '*_scarlet_img.fits', '*_scarlet_segmask.fits', n_samples=sampleNumbers)\n",
    "    dataset_dicts[d] = loader.generate_dataset_dict(annotate_hsc).get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2f3c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code snippet for unregistering if you want to change something\n",
    "\"\"\"\n",
    "if \"astro_train\" in DatasetCatalog.list():\n",
    "    print('removing astro_train')\n",
    "    DatasetCatalog.remove(\"astro_train\")\n",
    "    #MetadataCatalog.remove(\"astro_train\")\n",
    "    \n",
    "if \"astro_test\" in DatasetCatalog.list():\n",
    "    print('removing astro_test')\n",
    "    DatasetCatalog.remove(\"astro_test\")\n",
    "    #MetadataCatalog.remove(\"astro_test\")\n",
    "\n",
    "if \"astro_val\" in DatasetCatalog.list():\n",
    "    print('removing astro_val')\n",
    "    DatasetCatalog.remove(\"astro_val\")\n",
    "    #MetadataCatalog.remove(\"astro_val\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9bb953",
   "metadata": {},
   "source": [
    "### A note on classes\n",
    "\n",
    "In this demo, we assume one class for all objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d28831b-1ea3-44e4-ab90-0ee80ae2a93e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Visualize Ground Truth Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cca74ce-db2e-42cf-bc85-969562719115",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nsample = 1\n",
    "maxInd = sampleNumbers\n",
    "if maxInd == -1:\n",
    "    maxInd = 20\n",
    "randInd = np.random.randint(0, maxInd, nsample)\n",
    "fig = plt.figure(figsize=(8, 8 * nsample * 2))\n",
    "i = 0\n",
    "for ind in randInd:\n",
    "    # Need to increase ceil_percentile if the data are saturating!\n",
    "    d = dataset_dicts[\"train\"][ind]\n",
    "    filenames = [d[\"filename_G\"], d[\"filename_R\"], d[\"filename_I\"]]\n",
    "    img = toolkit.read_image_hsc(filenames, normalize=\"astrolupton\", stretch=0.5, Q=10)\n",
    "    visualizer = Visualizer(img, metadata=astrotrain_metadata)\n",
    "    out = visualizer.draw_dataset_dict(d)\n",
    "    ax1 = plt.subplot(nsample * 2, 1, 2 * i + 1)\n",
    "    ax1.imshow(out.get_image(), origin=\"upper\")\n",
    "    ax1.axis(\"off\")\n",
    "    ax2 = plt.subplot(nsample * 2, 1, 2 * i + 2)\n",
    "    ax2.imshow(img)\n",
    "    ax2.axis(\"off\")\n",
    "    i += 1\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db2ab22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 5))\n",
    "bins = 25\n",
    "# 91,28, 38 are  bad examples\n",
    "d = dataset_dicts[\"train\"][1]\n",
    "filenames = [d[\"filename_G\"], d[\"filename_R\"], d[\"filename_I\"]]\n",
    "\n",
    "img = toolkit.read_image_hsc(filenames, normalize=\"astrolupton\", stretch=0.5, Q=10)\n",
    "ax.hist(img[:, :, 0].flatten(), histtype=\"step\", bins=bins, log=True, color=\"r\", lw=2, zorder=1, label=\"i\")\n",
    "ax.hist(\n",
    "    img[:, :, 1].flatten(),\n",
    "    histtype=\"step\",\n",
    "    bins=bins,\n",
    "    log=True,\n",
    "    color=\"g\",\n",
    "    lw=2,\n",
    "    linestyle=\"-.\",\n",
    "    zorder=2,\n",
    "    label=\"r\",\n",
    ")\n",
    "ax.hist(\n",
    "    img[:, :, 2].flatten(),\n",
    "    histtype=\"step\",\n",
    "    bins=bins,\n",
    "    log=True,\n",
    "    color=\"b\",\n",
    "    lw=2,\n",
    "    linestyle=\"dashed\",\n",
    "    zorder=3,\n",
    "    label=\"g\",\n",
    ")\n",
    "ax.set_xlabel(\"Value\", fontsize=20)\n",
    "ax.set_ylabel(\"Count\", fontsize=20)\n",
    "ax.legend(fontsize=18)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8892af2c-0329-4072-979a-79b4b66f63e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Loading and Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005f3331-66f4-49d4-9d44-5ca832014d11",
   "metadata": {},
   "source": [
    "Below, we create the function train_mapper, which takes one of the metadata dictionaries, reads in the corresponding image, and applies custom\n",
    "augmentations.  It will output a new dictionary that will be fed into the model. You can see an example of the augmentations working below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e6d44c-45b4-42b7-a7af-516f6a1f631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepdisc.astrodet.detectron import _transform_to_aug\n",
    "\n",
    "\n",
    "def train_mapper(dataset_dict):\n",
    "\n",
    "    dataset_dict = copy.deepcopy(dataset_dict)  # it will be modified by code below\n",
    "    filenames = [dataset_dict[\"filename_G\"], dataset_dict[\"filename_R\"], dataset_dict[\"filename_I\"]]\n",
    "    image = toolkit.read_image_hsc(filenames, normalize=\"astrolupton\", stretch=0.5, Q=10)\n",
    "\n",
    "    augs = detectron_addons.KRandomAugmentationList(\n",
    "        [\n",
    "            # my custom augs\n",
    "            T.RandomRotation([-90, 90, 180], sample_style=\"choice\"),\n",
    "            T.RandomFlip(prob=0.5),\n",
    "            T.RandomFlip(prob=0.5, horizontal=False, vertical=True),\n",
    "            # detectron_addons.CustomAug(gaussblur,prob=1.0),\n",
    "            # detectron_addons.CustomAug(addelementwise,prob=1.0)\n",
    "            # CustomAug(white),\n",
    "        ],\n",
    "        k=-1,\n",
    "        cropaug=_transform_to_aug(\n",
    "            T.CropTransform(\n",
    "                image.shape[1] // 4, image.shape[0] // 4, image.shape[1] // 2, image.shape[0] // 2\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Data Augmentation\n",
    "    auginput = T.AugInput(image)\n",
    "    # Transformations to model shapes\n",
    "    transform = augs(auginput)\n",
    "    image = torch.from_numpy(auginput.image.copy().transpose(2, 0, 1))\n",
    "    annos = [\n",
    "        utils.transform_instance_annotations(annotation, [transform], image.shape[1:])\n",
    "        for annotation in dataset_dict.pop(\"annotations\")\n",
    "    ]\n",
    "\n",
    "    instances = utils.annotations_to_instances(annos, image.shape[1:])\n",
    "    instances = utils.filter_empty_instances(instances)\n",
    "\n",
    "    return {\n",
    "        # create the format that the model expects\n",
    "        \"image\": image,\n",
    "        \"image_shaped\": auginput.image,\n",
    "        \"height\": 1050,\n",
    "        \"width\": 1050,\n",
    "        \"image_id\": dataset_dict[\"image_id\"],\n",
    "        \"instances\": instances,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccb9dfb-80f6-4612-927e-5d11fb846331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.structures import BoxMode\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10 * 2, 10))\n",
    "\n",
    "dictionary = iter(dataset_dicts[\"train\"])\n",
    "d = next(dictionary)\n",
    "filenames = [d[\"filename_G\"], d[\"filename_R\"], d[\"filename_I\"]]\n",
    "\n",
    "img = toolkit.read_image_hsc(filenames, normalize=\"astrolupton\", stretch=0.5, Q=10)\n",
    "visualizer = Visualizer(img, metadata=astrotrain_metadata, scale=1)\n",
    "# Get the ground truth boxes\n",
    "gt_boxes = np.array([a[\"bbox\"] for a in d[\"annotations\"]])\n",
    "# Convert to the mode visualizer expects\n",
    "gt_boxes = BoxMode.convert(gt_boxes, BoxMode.XYWH_ABS, BoxMode.XYXY_ABS)\n",
    "out = visualizer.overlay_instances(boxes=gt_boxes)\n",
    "axs[0].imshow(out.get_image())\n",
    "axs[0].axis(\"off\")\n",
    "\n",
    "aug_d = train_mapper(d)\n",
    "img_aug = aug_d[\"image_shaped\"]\n",
    "visualizer = Visualizer(img_aug, metadata=astrotrain_metadata, scale=1)\n",
    "print(img_aug.shape)\n",
    "# Convert to the mode visualizer expects\n",
    "out = visualizer.overlay_instances(boxes=aug_d[\"instances\"].gt_boxes)\n",
    "axs[1].imshow(out.get_image())\n",
    "axs[1].axis(\"off\")\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc1328b-38a2-4900-8cd3-9ad3c5a9f318",
   "metadata": {},
   "source": [
    "You may have noticed the `train_mapper` function above is similar to the one used in the demo_decam notebook.  We've created the `ImageReader` and `DataMapper` class to generalize the dataloading.  You can check out the code to see the details.  We will use these classes during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0bcc02-27be-48f6-a20d-1063e768239c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepdisc.model.loaders as loaders\n",
    "from deepdisc.data_format.image_readers import HSCImageReader\n",
    "from deepdisc.data_format.augment_image import train_augs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89d92dc-5400-453e-8d85-2cd58a474f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function will take a dictionary and return the necessary file path(s) to read in the data\n",
    "\n",
    "def key_mapper(dataset_dict):\n",
    "    key = [dataset_dict[\"filename_G\"], dataset_dict[\"filename_R\"], dataset_dict[\"filename_I\"]]\n",
    "    return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f5d735-61a4-4c14-80f7-b2440d9be5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = loaders.DictMapper                                # DictMapper class to read in the dictionaries and reformat them for the model\n",
    "reader = HSCImageReader(norm=\"lupton\",stretch=0.5,     # ImageReader class to read the image from memory and apply contrast scalings\n",
    "                        Q=10, bandlist=[0,1,2])        \n",
    "mapper = tm(reader, key_mapper, train_augs).map_data   # Map (reformat) the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97671fa-f043-4e15-a3a2-acb41bd8bcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.structures import BoxMode\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10 * 2, 10))\n",
    "\n",
    "dictionary = iter(dataset_dicts[\"train\"])\n",
    "d = next(dictionary)\n",
    "img = reader(key_mapper(d))\n",
    "\n",
    "visualizer = Visualizer(img, metadata=astrotrain_metadata, scale=1)\n",
    "# Get the ground truth boxes\n",
    "gt_boxes = np.array([a[\"bbox\"] for a in d[\"annotations\"]])\n",
    "# Convert to the mode visualizer expects\n",
    "gt_boxes = BoxMode.convert(gt_boxes, BoxMode.XYWH_ABS, BoxMode.XYXY_ABS)\n",
    "out = visualizer.overlay_instances(boxes=gt_boxes)\n",
    "axs[0].imshow(out.get_image())\n",
    "axs[0].axis(\"off\")\n",
    "\n",
    "aug_d = mapper(d)\n",
    "img_aug = aug_d[\"image_shaped\"]\n",
    "visualizer = Visualizer(img_aug, metadata=astrotrain_metadata, scale=1)\n",
    "print(img_aug.shape)\n",
    "# Convert to the mode visualizer expects\n",
    "out = visualizer.overlay_instances(boxes=aug_d[\"instances\"].gt_boxes)\n",
    "axs[1].imshow(out.get_image())\n",
    "axs[1].axis(\"off\")\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a96bc1-a162-4739-a117-86759bd3eef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "901627b5-5ac0-4282-87f0-4a182259075b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db17cf5",
   "metadata": {},
   "source": [
    "We prepare for training by intializing a config object.  The we can take the intial weights from the pre-trained models in the model zoo.\n",
    "This setup is for demo purposes, so it does not follow a full training schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c31fb18-19e2-493c-91ce-bacf224bb41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepdisc.training.trainers import (\n",
    "    return_evallosshook,\n",
    "    return_lazy_trainer,\n",
    "    return_optimizer,\n",
    "    return_savehook,\n",
    "    return_schedulerhook,\n",
    ")\n",
    "\n",
    "from deepdisc.model.models import return_lazy_model\n",
    "\n",
    "import deepdisc.model.loaders as loaders\n",
    "from deepdisc.data_format.image_readers import HSCImageReader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d7c7a1-6f0d-4e8f-aa26-a912308c011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgfile = '../configs/solo/demo_r50_hsc.py'          # The config file which contains information about the model \n",
    "cfg = LazyConfig.load(cfgfile)                       # Load in the config\n",
    "model = return_lazy_model(cfg,freeze=False)          # Build the model from the config specifications\n",
    "cfg.optimizer.params.model = model                   # Set up the training optimizer\n",
    "optimizer = return_optimizer(cfg)\n",
    "\n",
    "\n",
    "\n",
    "loader = loaders.return_train_loader(cfg, mapper)      # Set up the loader, which formats the data to be fed into the model\n",
    "\n",
    "schedulerHook = return_schedulerhook(optimizer)      # Create a \"hook\" which will set up the scheduler to control learning rates\n",
    "saveHook = return_savehook(\"model_temp\")             # Create a \"hook\" which will save the model\n",
    "hookList = [saveHook, schedulerHook]                 \n",
    "\n",
    "cfg.train.init_checkpoint = \"detectron2://ImageNetPretrained/MSRA/R-50.pkl\"   #Initialize the model weights from a pre-trained model\n",
    "\n",
    "\n",
    "cfg.OUTPUT_DIR ='./'                                 #Set the output directory\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b531eed-aff5-4bd0-a13d-e794888f35bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hack if you get SSL certificate error\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "import warnings\n",
    "\n",
    "try:\n",
    "    # ignore ShapelyDeprecationWarning from fvcore\n",
    "    # This comes from the cropping\n",
    "    from shapely.errors import ShapelyDeprecationWarning\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\", category=ShapelyDeprecationWarning)\n",
    "\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bb398d-d9bd-4790-8879-43db9a81d56c",
   "metadata": {},
   "source": [
    "Now we can train the model!  We set up a trainer and tell it how often to output and when to stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce596b6-a8cf-44e9-8fd7-248ae3471be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer = toolkit.NewAstroTrainer(model, loader, optimizer, cfg)\n",
    "#trainer.register_hooks(hookList)\n",
    "trainer = return_lazy_trainer(model, loader, optimizer, cfg, hookList)\n",
    "trainer.set_period(10)  # print loss every 10 iterations\n",
    "trainer.train(0, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7d9200-a29d-4eb8-8982-8527b74a5bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 5))\n",
    "ax.plot(trainer.lossList, label=r\"$L_{\\rm{tot}}$\")\n",
    "ax.legend(loc=\"upper right\")\n",
    "ax.set_xlabel(\"training epoch\", fontsize=20)\n",
    "ax.set_ylabel(\"loss\", fontsize=20)\n",
    "ax.set_ylim(0,10)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c69b958",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc5bb80-1016-4aa1-bce1-cd0f655e35c8",
   "metadata": {},
   "source": [
    "We can use the same config to load the model after training.  Just change the path to the model weights.  We create a predictor class to feed in the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ef9f74-2c04-4699-acfc-bbfb5cc493b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgfile = '../configs/solo/demo_r50_hsc.py'\n",
    "cfg = LazyConfig.load(cfgfile)\n",
    "cfg.OUTPUT_DIR = './'\n",
    "cfg.train.init_checkpoint = os.path.join(cfg.OUTPUT_DIR, \"model_temp.pth\")\n",
    "\n",
    "#change these to play with the detection sensitivity\n",
    "#model.roi_heads.box_predictor.test_score_thresh = 0.3\n",
    "#model.roi_heads.box_predictor.test_nms_thresh = 0.5\n",
    "\n",
    "predictor = toolkit.AstroPredictor(cfg)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11e59da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "nsample = 1\n",
    "fig = plt.figure(figsize=(30, 15 * nsample))\n",
    "\n",
    "for i, d in enumerate(random.sample(dataset_dicts[\"train\"], nsample)):\n",
    "    filenames = [d[\"filename_G\"], d[\"filename_R\"], d[\"filename_I\"]]\n",
    "    img = toolkit.read_image_hsc(filenames, normalize=\"astrolupton\", stretch=0.5, Q=10)\n",
    "    print(\"total instances:\", len(d[\"annotations\"]))\n",
    "    v0 = Visualizer(\n",
    "        img,\n",
    "        metadata=astrotest_metadata,\n",
    "        scale=1,\n",
    "        instance_mode=ColorMode.IMAGE_BW,  # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
    "    )\n",
    "    groundTruth = v0.draw_dataset_dict(d)\n",
    "\n",
    "    ax1 = plt.subplot(nsample, 2, 2 * i + 1)\n",
    "    ax1.imshow(groundTruth.get_image())\n",
    "    ax1.axis(\"off\")\n",
    "\n",
    "    v1 = Visualizer(\n",
    "        img,\n",
    "        metadata=astrotest_metadata,\n",
    "        scale=1,\n",
    "        instance_mode=ColorMode.IMAGE_BW,  # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
    "    )\n",
    "    outputs = predictor(\n",
    "        img\n",
    "    )  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
    "    out = v1.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    print(\"detected instances:\", len(outputs[\"instances\"].pred_boxes))\n",
    "    print(\"\")\n",
    "    ax1 = plt.subplot(nsample, 2, 2 * i + 2)\n",
    "    ax1.imshow(out.get_image())\n",
    "    ax1.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c0cce1-ac29-4e73-967d-72a547edcd10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22ec03e-557e-4e64-ba09-f2e6ad36460a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7d8a50-cca7-475a-9b6d-7c955145b533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66d34854",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "\n",
    "We'll measure the AP score for detected objects below.  Don't expect it to be too good, since you need to train a large amount of data for a while to get the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d98ce5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mapper(dataset_dict, **read_image_args):\n",
    "\n",
    "    dataset_dict = copy.deepcopy(dataset_dict)  # it will be modified by code below\n",
    "    filenames = [d[\"filename_G\"], d[\"filename_R\"], d[\"filename_I\"]]\n",
    "    image = toolkit.read_image_hsc(filenames, normalize=\"astrolupton\", stretch=0.5, Q=100)\n",
    "    augs = T.AugmentationList([])\n",
    "    # Data Augmentation\n",
    "    auginput = T.AugInput(image)\n",
    "    # Transformations to model shapes\n",
    "    transform = augs(auginput)\n",
    "    image = torch.from_numpy(auginput.image.copy().transpose(2, 0, 1))\n",
    "    annos = [\n",
    "        utils.transform_instance_annotations(annotation, [transform], image.shape[1:])\n",
    "        for annotation in dataset_dict.pop(\"annotations\")\n",
    "    ]\n",
    "    return {\n",
    "        # create the format that the model expects\n",
    "        \"image\": image,\n",
    "        \"image_shaped\": auginput.image,\n",
    "        \"height\": 1050,\n",
    "        \"width\": 1050,\n",
    "        \"image_id\": dataset_dict[\"image_id\"],\n",
    "        \"instances\": utils.annotations_to_instances(annos, image.shape[1:]),\n",
    "        \"annotations\": annos,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac18542",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from detectron2.evaluation import inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "evaluator = toolkit.COCOEvaluatorRecall(\n",
    "    \"astro_test\", use_fast_impl=True, allow_cached_coco=False, output_dir=cfg.OUTPUT_DIR\n",
    ")\n",
    "\n",
    "test_loader = data.build_detection_test_loader(cfg, \"astro_test\", mapper=test_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8836fdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = inference_on_dataset(predictor.model, test_loader, evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc6c82c-b728-4885-a62e-09ee6c3b5d66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(results[\"bbox\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213eff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_type = \"bbox\"\n",
    "cls_names = [\"object\"]\n",
    "# take star out april\n",
    "results_per_category = results[ap_type][\"results_per_category\"]\n",
    "\n",
    "#fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "fig = plt.figure(figsize=(7, 4))\n",
    "# axs = plt.subplot(1, 1, figsize=(10, 10))\n",
    "axs = fig.add_subplot(111)\n",
    "# axs = axs.flatten()\n",
    "\n",
    "ious = np.linspace(0.50, 0.95, 10)\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(ious)))\n",
    "\n",
    "# Plot precision recall\n",
    "for j, precision_class in enumerate(results_per_category):\n",
    "    precision_shape = np.shape(precision_class)\n",
    "    for i in range(precision_shape[0]):\n",
    "        # precision has dims (iou, recall, cls, area range, max dets)\n",
    "        # area range index 0: all area ranges\n",
    "        # max dets index -1: typically 100 per image\n",
    "        p_dat = precision_class[i, :, j, 0, -1]\n",
    "        # Hide vanishing precisions\n",
    "        mask = p_dat > 0\n",
    "        # Only keep first occurance of 0 value in array\n",
    "        mask[np.cumsum(~mask) == 1] = True\n",
    "        p = p_dat[mask]\n",
    "        # Recall points\n",
    "        r = np.linspace(0, 1, len(p))\n",
    "        dr = np.diff(np.linspace(0, 1, len(p_dat)))[0]  # i think\n",
    "        # Plot\n",
    "        iou = np.around(ious[i], 2)\n",
    "        AP = 100 * np.sum(p * dr)\n",
    "        axs.plot(r, p, label=r\"${\\rm{AP}}_{%.2f} = %.1f$\" % (iou, AP), color=colors[i], lw=2)\n",
    "        axs.set_xlabel(\"Recall\", fontsize=20)\n",
    "        axs.set_ylabel(\"Precision\", fontsize=20)\n",
    "        axs.set_xlim(0, 1.1)\n",
    "        axs.set_ylim(0, 1.1)\n",
    "        axs.legend(fontsize=10, title=f\"{cls_names[j]}\", bbox_to_anchor=(1.35, 1.0))\n",
    "\n",
    "        # axs[j].plot(r, p, label=r'${\\rm{AP}}_{%.2f} = %.1f$' % (iou, AP), color=colors[i], lw=2)\n",
    "        # axs[j].set_xlabel('Recall', fontsize=20)\n",
    "        # axs[j].set_ylabel('Precision', fontsize=20)\n",
    "        # axs[j].set_xlim(0, 1.1)\n",
    "        # axs[j].set_ylim(0, 1.1)\n",
    "        # axs[j].legend(fontsize=10, title=f'{cls_names[j]}', bbox_to_anchor=(1.35, 1.0))\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9176b2a7",
   "metadata": {},
   "source": [
    "Real data has a lot more variation than simulations and requires more training for the networks to have good evaulation performance.  This demo is just to show how to set up the training.  We encourage you to add object classes, try different contrast scalings, and train for longer!  \n",
    "\n",
    "\n",
    "    \n",
    "  \n",
    "  You can also look at the content of the output below  \n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c4e99a-675a-40d8-a84b-d92de8f6d6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = iter(dataset_dicts[\"test\"])\n",
    "d = next(dictionary)\n",
    "img = reader(key_mapper(d))\n",
    "\n",
    "\n",
    "outputs = predictor(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe8b3ef-f623-42c7-8532-c9dbf680c996",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs['instances'].get_fields().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9ef2ac-7556-4377-93b7-a14a985d101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs['instances'].scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9279207-4862-469f-9ad3-2872815988f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8527d46-c621-4bf2-8077-c6d22bb64205",
   "metadata": {},
   "source": [
    "Try to rerun with a different model.  You can do this by using the config in `/configs/solo/demo_swin_hsc.py`  \n",
    "\n",
    "If you want to use a pre-trained model with this config, you will need to download it here https://dl.fbaipublicfiles.com/detectron2/ViTDet/COCO/cascade_mask_rcnn_swin_b_in21k/f342979038/model_final_246a82.pkl  \n",
    "\n",
    "You will need to change the `cfg.train.init_checkpoint` to the path of the downloaded pre-trained model  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ad2e13-5098-46f6-8eb8-f8315dbf3d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e920b9-8854-4810-9f4b-71d0d6557116",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-ddrailnv]",
   "language": "python",
   "name": "conda-env-.conda-ddrailnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
