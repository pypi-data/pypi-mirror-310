from dataclasses import dataclass
from enum import Enum
from typing import Any, TypedDict

import numpy as np
import pandas as pd
from datasets import Dataset
from numpy.typing import NDArray
from PIL import Image
from torch.utils.data import DataLoader as TorchDataLoader
from torch.utils.data import Dataset as TorchDataset

InputType = str | Image.Image
InputTypeList = (
    list[str | Image.Image] | list[str] | list[Image.Image] | list[InputType]
)  # this is not equivalent to list[InputType]


def _repr_np(embedding: np.ndarray) -> str:
    if isinstance(embedding, np.ndarray):
        return f"<array.{embedding.dtype}{embedding.shape}>"
    else:
        raise ValueError(f"Unsupported type: {type(embedding)}")


@dataclass
class Memory:
    """
    The base class for a labeled memory. This includes fields that are ALWAYS required.
    """

    value: InputType
    """The value used to generate the embedding for looking up this memory."""

    embedding: np.ndarray
    """The embedding of the memory value, automatically generated by the Memoryset model."""

    memory_id: str
    """The UUID of the memory in the table, automatically generated by the Memoryset."""

    memory_version: int
    """The version of the memory, automatically maintained by the Memoryset."""

    metadata: dict[str, Any]
    """Metadata associated with the memory that is not used in the model."""

    def __getitem__(self, key):
        return getattr(self, key)

    def __setitem__(self, key, value):
        setattr(self, key, value)

    def __repr__(self) -> str:
        return "".join(
            [
                "Memory(\n",
                f"    value={(chr(39) + self.value + chr(39)) if isinstance(self.value, str) else '<Image>'},\n",
                f"    metadata={self.metadata},\n" if self.metadata else "",
                f"    embedding={_repr_np(self.embedding)},\n",
                f"    memory_id={self.memory_id},\n",
                f"    memory_version={self.memory_version},\n",
                ")",
            ]
        )


@dataclass
class _LabeledMemoryFields:
    label: int
    """The label of the memory."""

    label_name: str | None = None
    """The human-readable name of the label."""


@dataclass
class LabeledMemory(_LabeledMemoryFields, Memory):
    """
    A labeled memory is a single item that can be stored in the database and has a label.
    """

    def __repr__(self) -> str:
        return "".join(
            [
                "LabeledMemory(\n",
                f"    value={(chr(39) + self.value + chr(39)) if isinstance(self.value, str) else '<Image>'},\n",
                f"    label={('<' + self.label_name + ': ' + str(self.label) + '>') if self.label_name else str(self.label)},\n",
                f"    metadata={self.metadata},\n" if self.metadata else "",
                f"    embedding={_repr_np(self.embedding)},\n",
                f"    memory_id={self.memory_id},\n",
                f"    memory_version={self.memory_version},\n",
                ")",
            ]
        )


@dataclass
class _RequiredLookupProperties:
    lookup_score: float
    """The similarity score between the query and the memory."""


@dataclass
class _OptionalLookupProperties:
    reranker_score: float | None = None
    """
    The similarity score assigned by the reranker.

    Note:
        This will be automatically generated if a reranker is attached to the memoryset.
    """

    reranker_embedding: np.ndarray | None = None
    """
    The reranker embedding for this memory value.

    Note:
        This will be automatically generated if a reranker is attached to the memoryset.
    """

    attention_weight: float | None = None
    """
    The attention the model gave to this memory lookup.

    Note:
        This is not provided during lookup but can instead be optionally added by the model during
        its forward pass to store for later analysis.
    """


@dataclass
class MemoryLookup(
    _OptionalLookupProperties,
    Memory,
    _RequiredLookupProperties,
):
    """
    Single labeled memory lookup result.
    """

    def __repr__(self) -> str:
        return "".join(
            [
                "LabeledMemoryLookup(\n",
                f"    value={(chr(39) + self.value + chr(39)) if isinstance(self.value, str) else '<Image>'},\n",
                f"    metadata={self.metadata},\n" if self.metadata else "",
                f"    embedding={_repr_np(self.embedding)},\n",
                f"    memory_id={self.memory_id},\n",
                f"    memory_version={self.memory_version},\n",
                f"    lookup_score={self.lookup_score},\n",
                f"    reranker_score={self.reranker_score},\n" if self.reranker_score else "",
                f"    reranker_embedding={_repr_np(self.reranker_embedding)},\n" if self.reranker_embedding else "",
                f"    attention_weight={self.attention_weight},\n" if self.attention_weight else "",
                ")",
            ]
        )


@dataclass
class LabeledMemoryLookup(
    _OptionalLookupProperties,
    _LabeledMemoryFields,
    Memory,
    _RequiredLookupProperties,
):
    """
    Single labeled memory lookup result.
    """

    def __repr__(self) -> str:
        return "".join(
            [
                "LabeledMemoryLookup(\n",
                f"    value={(chr(39) + self.value + chr(39)) if isinstance(self.value, str) else '<Image>'},\n",
                f"    label={('<' + self.label_name + ': ' + str(self.label) + '>') if self.label_name else str(self.label)},\n",
                f"    metadata={self.metadata},\n" if self.metadata else "",
                f"    embedding={_repr_np(self.embedding)},\n",
                f"    memory_id={self.memory_id},\n",
                f"    memory_version={self.memory_version},\n",
                f"    lookup_score={self.lookup_score},\n",
                f"    reranker_score={self.reranker_score},\n" if self.reranker_score else "",
                f"    reranker_embedding={_repr_np(self.reranker_embedding)},\n" if self.reranker_embedding else "",
                f"    attention_weight={self.attention_weight},\n" if self.attention_weight else "",
                ")",
            ]
        )


DatasetLike = (
    list[tuple[InputType, int]]
    | list[tuple[str, int]]
    | list[tuple[Image.Image, int]]
    | pd.DataFrame
    | Dataset
    | TorchDataset
    | TorchDataLoader
    | LabeledMemory
    | list[LabeledMemory]
    | dict
    | list[dict]
)


class LookupReturnType(str, Enum):
    COLUMNS = "columns"
    ROWS = "rows"


class LabeledMemoryLookupColumnResult(TypedDict):
    input_embeddings: list[NDArray[np.float32]]  # batch_size x embedding_dim
    memories_values: list[InputTypeList]  # batch_size x num_memories
    memories_labels: list[list[int]]  # batch_size x num_memories
    memories_embeddings: list[list[NDArray[np.float32]]]  # batch_size x num_memories x embedding_dim
    memories_ids: list[list[str]]  # batch_size x num_memories
    memories_versions: list[list[int]]  # batch_size x num_memories
    memories_metadata: list[list[dict[str, Any]]]  # batch_size x num_memories
    memories_lookup_scores: list[list[float]]  # batch_size x num_memories
    memories_reranker_scores: list[list[float | None]]  # batch_size x num_memories
    # TODO: add these back once the reranker can return embeddings
    # input_reranker_embeddings: list[NDArray[np.float32] | None]  # batch_size x embedding_dim
    # memories_reranker_embeddings: list[list[NDArray[np.float32] | None]]  # batch_size x num_memories x embedding_dim
